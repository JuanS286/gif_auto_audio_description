{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5790532-a5f6-4a18-a548-9c9110886e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "from google.cloud import storage\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "GCS_BUCKET_NAME = 'juanmodeltry'  # Replace with your GCS bucket name if different\n",
    "GCS_METADATA_PATH = 'metadata.json'  # Path to metadata.json within the bucket\n",
    "GCS_DESTINATION_FOLDER = 'gifs/'  # Destination folder in the bucket\n",
    "LOCAL_DOWNLOAD_FOLDER = 'downloaded_gifs/'\n",
    "TEXT_FILE_FOLDER = 'textfiles/'\n",
    "\n",
    "# Temporary local folder\n",
    "SAMPLE_SIZE = 100\n",
    "TRAIN_SPLIT = 70\n",
    "VAL_SPLIT = 10\n",
    "TEST_SPLIT = 10\n",
    "\n",
    "# Split files\n",
    "TRAIN_SPLIT_FILE = 'train.txt'\n",
    "VAL_SPLIT_FILE = 'val.txt'\n",
    "TEST_SPLIT_FILE = 'test.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0080e74-43a1-49e3-8022-76cc1c6743b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_dir(directory):\n",
    "    \"\"\"Ensure that a directory exists.\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def load_metadata_from_gcs(bucket_name, blob_name):\n",
    "    \"\"\"Load metadata.json directly from GCS.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    \n",
    "    if not blob.exists():\n",
    "        raise FileNotFoundError(f\"{blob_name} not found in bucket {bucket_name}.\")\n",
    "    \n",
    "    content = blob.download_as_text()\n",
    "    data = json.loads(content)\n",
    "    return data\n",
    "\n",
    "def sample_gifs(data, sample_size):\n",
    "    \"\"\"Randomly sample a specified number of GIFs.\"\"\"\n",
    "    return random.sample(data, sample_size)\n",
    "\n",
    "def split_gifs(sampled_gifs, train, val, test):\n",
    "    \"\"\"Split sampled GIFs into train, val, and test sets.\"\"\"\n",
    "    train_gifs = sampled_gifs[:train]\n",
    "    val_gifs = sampled_gifs[train:train+val]\n",
    "    test_gifs = sampled_gifs[train+val:train+val+test]\n",
    "    return train_gifs, val_gifs, test_gifs\n",
    "\n",
    "def download_gif(url, dest_path):\n",
    "    \"\"\"Download a GIF from a URL to a local path.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        with open(dest_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "        return False\n",
    "\n",
    "def upload_to_gcs(bucket, source_file, destination_blob):\n",
    "    \"\"\"Upload a local file to GCS.\"\"\"\n",
    "    try:\n",
    "        blob = bucket.blob(destination_blob)\n",
    "        blob.upload_from_filename(source_file)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to upload {source_file} to {destination_blob}: {e}\")\n",
    "        return False\n",
    "\n",
    "def write_split_file(split_file, gif_filenames):\n",
    "    \"\"\"Write a list of GIF filenames to a split text file.\"\"\"\n",
    "    with open(split_file, 'w') as f:\n",
    "        for filename in gif_filenames:\n",
    "            f.write(f\"{filename}\\n\")\n",
    "\n",
    "def main():\n",
    "    # Step 1: Setup local directories\n",
    "    ensure_dir(LOCAL_DOWNLOAD_FOLDER)\n",
    "\n",
    "    # Step 2: Load metadata from GCS\n",
    "    print(\"Loading metadata from GCS...\")\n",
    "    metadata = load_metadata_from_gcs(GCS_BUCKET_NAME, GCS_METADATA_PATH)\n",
    "    print(f\"Total GIFs available: {len(metadata)}\")\n",
    "    \n",
    "    if len(metadata) < SAMPLE_SIZE:\n",
    "        print(f\"Not enough GIFs in metadata. Required: {SAMPLE_SIZE}, Available: {len(metadata)}\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Sample GIFs\n",
    "    print(f\"Sampling {SAMPLE_SIZE} GIFs...\")\n",
    "    sampled_gifs = sample_gifs(metadata, SAMPLE_SIZE)\n",
    "\n",
    "    # Step 4: Split GIFs\n",
    "    train_gifs, val_gifs, test_gifs = split_gifs(sampled_gifs, TRAIN_SPLIT, VAL_SPLIT, TEST_SPLIT)\n",
    "    print(f\"Training GIFs: {len(train_gifs)}, Validation GIFs: {len(val_gifs)}, Testing GIFs: {len(test_gifs)}\")\n",
    "\n",
    "    # Step 5: Initialize GCS client\n",
    "    print(\"Initializing Google Cloud Storage client...\")\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(GCS_BUCKET_NAME)\n",
    "    if not bucket.exists():\n",
    "        print(f\"Bucket {GCS_BUCKET_NAME} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Step 6: Upload all GIFs to 'gifs/' folder\n",
    "    print(\"Uploading GIFs to GCS...\")\n",
    "    for gif in tqdm(sampled_gifs, desc=\"Uploading GIFs\"):\n",
    "        gif_id = gif['id']\n",
    "        url = gif['url']\n",
    "        gif_filename = f\"{gif_id}.gif\"\n",
    "        local_path = os.path.join(LOCAL_DOWNLOAD_FOLDER, gif_filename)\n",
    "        gcs_path = os.path.join(GCS_DESTINATION_FOLDER, gif_filename)\n",
    "\n",
    "        # Download GIF\n",
    "        success = download_gif(url, local_path)\n",
    "        if not success:\n",
    "            continue  # Skip to next GIF if download failed\n",
    "\n",
    "        # Upload to GCS\n",
    "        success = upload_to_gcs(bucket, local_path, gcs_path)\n",
    "        if success:\n",
    "            pass  # GIF uploaded successfully\n",
    "        else:\n",
    "            print(f\"Failed to upload {gif_filename} to GCS.\")\n",
    "\n",
    "        # Remove local file after upload to save space\n",
    "        os.remove(local_path)\n",
    "\n",
    "    # Step 7: Write split files\n",
    "    print(\"Writing split text files...\")\n",
    "    train_filenames = [f\"{gif['id']}.gif\" for gif in train_gifs]\n",
    "    val_filenames = [f\"{gif['id']}.gif\" for gif in val_gifs]\n",
    "    test_filenames = [f\"{gif['id']}.gif\" for gif in test_gifs]\n",
    "\n",
    "    write_split_file(TRAIN_SPLIT_FILE, train_filenames)\n",
    "    write_split_file(VAL_SPLIT_FILE, val_filenames)\n",
    "    write_split_file(TEST_SPLIT_FILE, test_filenames)\n",
    "\n",
    "    # Step 8: Upload split files to GCS\n",
    "    print(\"Uploading split text files to GCS...\")\n",
    "    for split_name, split_file in zip(['train', 'val', 'test'], [TRAIN_SPLIT_FILE, VAL_SPLIT_FILE, TEST_SPLIT_FILE]):\n",
    "        gcs_split_path = os.path.join(TEXT_FILE_FOLDER, split_file)\n",
    "        success = upload_to_gcs(bucket, split_file, gcs_split_path)\n",
    "        if success:\n",
    "            os.remove(split_file)  # Remove local split file after upload\n",
    "        else:\n",
    "            print(f\"Failed to upload {split_file} to GCS.\")\n",
    "\n",
    "    print(\"All tasks completed successfully!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3284efbb-89db-4b93-ab6c-f972bca9a81b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from GCS...\n",
      "Total GIFs available: 125782\n",
      "Sampling 100 GIFs...\n",
      "Training GIFs: 70, Validation GIFs: 10, Testing GIFs: 10\n",
      "Initializing Google Cloud Storage client...\n",
      "Uploading GIFs to GCS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading GIFs: 100%|██████████| 100/100 [01:00<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing split text files...\n",
      "Uploading split text files to GCS...\n",
      "All tasks completed successfully!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
