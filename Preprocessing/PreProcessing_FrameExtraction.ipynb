{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsnFtfEM5nyq",
        "outputId": "78bdb029-d23e-47c4-d2f4-f252aefa0b89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.27.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.32.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.65.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.24.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.8.30)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-cloud-storage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "import imageio\n",
        "import cv2\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from google.cloud import storage\n",
        "from google.colab import auth\n",
        "import tempfile\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set up Google Cloud Storage client\n",
        "storage_client = storage.Client()\n",
        "bucket_name = 'gif-bucket-1000'\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "def resize_and_normalize_frame(frame, target_size=(128, 128)):\n",
        "    \"\"\"Resize and normalize the frame while preserving aspect ratio.\"\"\"\n",
        "    original_height, original_width = frame.shape[:2]\n",
        "    aspect_ratio = original_width / original_height\n",
        "\n",
        "    if aspect_ratio > 1:  # Wider than tall\n",
        "        new_width = target_size[0]\n",
        "        new_height = int(target_size[0] / aspect_ratio)\n",
        "    else:  # Taller than wide or square\n",
        "        new_width = int(target_size[1] * aspect_ratio)\n",
        "        new_height = target_size[1]\n",
        "\n",
        "    resized_frame = cv2.resize(frame, (new_width, new_height))\n",
        "\n",
        "    # Calculate padding\n",
        "    delta_w = target_size[0] - new_width\n",
        "    delta_h = target_size[1] - new_height\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    # Add padding to maintain the target size\n",
        "    normalized_frame = cv2.copyMakeBorder(resized_frame, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "    normalized_frame = normalized_frame.astype(np.float32) / 255.0\n",
        "\n",
        "    return normalized_frame\n",
        "\n",
        "def augment_frame(frame):\n",
        "    \"\"\"Apply random data augmentation to the frame.\"\"\"\n",
        "    if np.random.rand() < 0.5:\n",
        "        frame = cv2.flip(frame, 1)  # Horizontal flip\n",
        "    if np.random.rand() < 0.5:\n",
        "        rows, cols = frame.shape[:2]\n",
        "        rotation_angle = np.random.randint(-10, 10)\n",
        "        M = cv2.getRotationMatrix2D((cols/2, rows/2), rotation_angle, 1)\n",
        "        frame = cv2.warpAffine(frame, M, (cols, rows))\n",
        "    return frame\n",
        "\n",
        "def extract_key_frames(frames, ssim_threshold=0.95, min_scene_change=10):\n",
        "    \"\"\"Extract key frames based on structural similarity.\"\"\"\n",
        "    key_frames = []\n",
        "    prev_frame = None\n",
        "    scene_change_counter = 0\n",
        "    scene_changes = []  # Initialize scene_changes here\n",
        "\n",
        "    for i, frame in enumerate(frames):\n",
        "        if not isinstance(frame, np.ndarray):\n",
        "            print(f\"Frame {i}: Not a valid NumPy array.\")\n",
        "            continue\n",
        "\n",
        "        if frame.size == 0 or len(frame.shape) != 3:\n",
        "            print(f\"Frame {i}: Empty or has invalid dimensions: {frame.shape if isinstance(frame, np.ndarray) else 'N/A'}\")\n",
        "            continue\n",
        "\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        if prev_frame is None:\n",
        "            key_frames.append(frame)\n",
        "            prev_frame = gray_frame\n",
        "            continue\n",
        "\n",
        "        similarity_score = ssim(prev_frame, gray_frame, data_range=1.0)\n",
        "\n",
        "        if similarity_score < ssim_threshold:\n",
        "            scene_change_counter += 1\n",
        "            if scene_change_counter >= min_scene_change:\n",
        "                key_frames.append(frame)\n",
        "                scene_changes.append(i)  # Add index to scene_changes\n",
        "                scene_change_counter = 0\n",
        "        else:\n",
        "            scene_change_counter = 0\n",
        "\n",
        "        prev_frame = gray_frame\n",
        "\n",
        "    return key_frames, scene_changes  # Return scene_changes\n",
        "\n",
        "\n",
        "def preprocess_gif(gif_file_name, gif_id):\n",
        "    \"\"\"Preprocesses a GIF from GCS, extracts key frames, and uploads them to the bucket.\"\"\"\n",
        "    try:\n",
        "        gif_blob = bucket.blob(os.path.join('gifs', gif_file_name))\n",
        "        gif_bytes = gif_blob.download_as_bytes()\n",
        "\n",
        "        with imageio.get_reader(BytesIO(gif_bytes), 'gif') as reader:\n",
        "            frame_count = reader.get_length()\n",
        "            try:\n",
        "                frame_rate = 1 / reader.get_meta_data()['duration']\n",
        "            except (KeyError, AttributeError, ZeroDivisionError):\n",
        "                frame_rate = 10\n",
        "\n",
        "            processed_frames = []\n",
        "            for frame in reader:\n",
        "                if frame.shape[-1] == 4:\n",
        "                    frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2RGB)\n",
        "                resized_frame = resize_and_normalize_frame(frame)\n",
        "                augmented_frame = augment_frame(resized_frame)\n",
        "                processed_frames.append(augmented_frame)\n",
        "\n",
        "        key_frames, scene_changes = extract_key_frames(processed_frames)\n",
        "\n",
        "        frame_paths = []\n",
        "        for i, frame in enumerate(key_frames):\n",
        "            # Construct the path for the frame in the bucket\n",
        "            frame_path = os.path.join('gif_frames', str(gif_id), f'frame_{i}.png')\n",
        "\n",
        "            # Create a new blob and upload the frame\n",
        "            frame_blob = bucket.blob(frame_path)\n",
        "            _, temp_local_filename = tempfile.mkstemp()\n",
        "            #cv2.imwrite(temp_local_filename, frame * 255)\n",
        "            frame = (frame * 255).astype(np.uint8)\n",
        "            imageio.imwrite(temp_local_filename, frame, format='PNG')\n",
        "            frame_blob.upload_from_filename(temp_local_filename)\n",
        "            os.remove(temp_local_filename)\n",
        "\n",
        "            frame_paths.append(frame_path)  # Store the GCS path\n",
        "\n",
        "        gif_data = {\n",
        "            'gif_id': gif_id,\n",
        "            'gif_file': gif_file_name,\n",
        "            'file_size': len(gif_bytes),  # Get file size from gif_bytes\n",
        "            'frame_count': frame_count,\n",
        "            'frame_rate': frame_rate,\n",
        "            'frames': frame_paths,  # Store paths to frames in GCS\n",
        "            'scene_changes': scene_changes,\n",
        "        }\n",
        "\n",
        "        return gif_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing GIF {gif_file_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_gifs(file_path):\n",
        "    \"\"\"Processes GIFs listed in a text file.\"\"\"\n",
        "    gif_data_list = []\n",
        "    gif_id_counter = 1\n",
        "    try:\n",
        "        # Download the file from GCS\n",
        "        blob = bucket.blob(file_path)\n",
        "        file_content = blob.download_as_string().decode('utf-8')\n",
        "\n",
        "        for line in file_content.splitlines():\n",
        "            gif_file_name = line.strip()\n",
        "            gif_data = preprocess_gif(gif_file_name, gif_id_counter)\n",
        "            if gif_data:\n",
        "                gif_data_list.append(gif_data)\n",
        "                gif_id_counter += 1\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_path}: {e}\")\n",
        "\n",
        "    return gif_data_list\n",
        "\n",
        "# Process GIFs for each data split\n",
        "train_data = process_gifs('train.txt')\n",
        "val_data = process_gifs('val.txt')\n",
        "test_data = process_gifs('test.txt')\n",
        "\n",
        "# Upload the data to JSON files in GCS\n",
        "def upload_json_to_gcs(data, filename):\n",
        "    \"\"\"Uploads a JSON object to GCS.\"\"\"\n",
        "    try:\n",
        "        json_blob = bucket.blob(filename)\n",
        "        json_blob.upload_from_string(json.dumps(data, indent=4), content_type='application/json')\n",
        "        print(f\"Uploaded {filename} to GCS\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading {filename} to GCS: {e}\")\n",
        "\n",
        "upload_json_to_gcs(train_data, 'train_data.json')\n",
        "upload_json_to_gcs(val_data, 'val_data.json')\n",
        "upload_json_to_gcs(test_data, 'test_data.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABwxcDDh6nAJ",
        "outputId": "b673849b-5408-47ae-aea2-8988f55fe0dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing GIF 53556.gif: No packer found from P to L\n",
            "Frame 0: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 1: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 2: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 3: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 4: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 5: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 6: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 7: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 8: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 9: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 10: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 11: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 12: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 13: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 14: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 15: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 16: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 17: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 18: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 19: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 20: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 21: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 22: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 23: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 24: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 25: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 26: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 27: Empty or has invalid dimensions: (128, 128)\n",
            "Frame 28: Empty or has invalid dimensions: (128, 128)\n",
            "Uploaded train_data.json to GCS\n",
            "Uploaded val_data.json to GCS\n",
            "Uploaded test_data.json to GCS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LpfJr7c97a8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}